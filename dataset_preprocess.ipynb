{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the dataset for FelineFlow\n",
    "The original Cats vs. Dogs dataset consists of more than 12,000 images, each of different sizes of cats alone! We need to modify the dataset to suit our needs accordingly.\n",
    "\n",
    "In this notebook, we will apply the following transformations:\n",
    "- Select 4096 images for training and testing.\n",
    "- Crop the images to a 1:1 aspect ratio.\n",
    "- Check if the images have a single cat, in frame using Haar Cascades (and choose another image otherwise)\n",
    "- Downscale the image to 128x128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to crop an image to 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_square(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    height, width = img.shape[:2]\n",
    "    if(height==width):\n",
    "        return img\n",
    "    if(height>width):\n",
    "        return img[(height-width)//2: (height+width)//2, :]\n",
    "    else:\n",
    "        return img[:, (width-height)//2: (width+height)//2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to resize the image to a specified resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, res):\n",
    "    return cv2.resize(img, res, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A module that recognises cat faces. We will be using the [Cat Frontal Face Haar Cascade](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalcatface_extended.xml) contributed by Joseph Howse provided on the OpenCV GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValidCat(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cascade = cv2.CascadeClassifier('./haarcascade_frontalcatface.xml')\n",
    "    faces = cascade.detectMultiScale(gray, 1.1, 3) #image, reject levels, level weight\n",
    "    return len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isValidCat(crop_square('./cats_source/122.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, a function to generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(input_dir, output_dir, res, num_images):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    img_paths = os.listdir(input_dir)\n",
    "    if(len(img_paths)<num_images):\n",
    "        raise Exception(\"Not enough images in source directory\")\n",
    "    \n",
    "    selected_paths = img_paths[:num_images]\n",
    "    for i in range(len(selected_paths)):\n",
    "        try:\n",
    "            destination_path = os.path.join(output_dir, str(i))+'.jpg'\n",
    "            cropped_image = crop_square(os.path.join(input_dir,selected_paths[i]))\n",
    "            if(not isValidCat(cropped_image)):\n",
    "                continue\n",
    "                            \n",
    "            resized_image = resize(cropped_image, res)\n",
    "            print(destination_path, 'saved')\n",
    "            cv2.imwrite(destination_path, resized_image)\n",
    "        except AttributeError:\n",
    "            i-=1\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify the parameters globally and watch the script work its magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not a cat\n",
      "./cats_processed\\1.jpg saved\n",
      "Not a cat\n",
      "./cats_processed\\3.jpg saved\n",
      "Not a cat\n",
      "./cats_processed\\5.jpg saved\n",
      "Not a cat\n",
      "./cats_processed\\7.jpg saved\n",
      "./cats_processed\\8.jpg saved\n",
      "./cats_processed\\9.jpg saved\n",
      "./cats_processed\\10.jpg saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./cats_source\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./cats_processed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[1;34m(input_dir, output_dir, res, num_images)\u001b[0m\n\u001b[0;32m     11\u001b[0m destination_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;28mstr\u001b[39m(i))\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m cropped_image \u001b[38;5;241m=\u001b[39m crop_square(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir,selected_paths[i]))\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[43misValidCat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped_image\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot a cat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36misValidCat\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      2\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      3\u001b[0m cascade \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./haarcascade_frontalcatface.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mcascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#image, reject levels, level weight\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_dataset('./cats_source', './cats_processed', (256,256), 4096)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
