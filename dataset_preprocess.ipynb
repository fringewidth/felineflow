{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process the dataset for FelineFlow\n",
    "The original Cats vs. Dogs dataset consists of more than 12,000 images, each of different sizes of cats alone! We need to modify the dataset to suit our needs accordingly.\n",
    "\n",
    "In this notebook, we will apply the following transformations:\n",
    "- Select 4096 images for training and testing.\n",
    "- Crop the images to a 1:1 aspect ratio.\n",
    "- Check if the images have a single cat, in frame using Haar Cascades (and choose another image otherwise)\n",
    "- Downscale the image to 128x128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to crop an image to 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_square(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    height, width = img.shape[:2]\n",
    "    if(height==width):\n",
    "        return img\n",
    "    if(height>width):\n",
    "        return img[(height-width)//2: (height+width)//2, :]\n",
    "    else:\n",
    "        return img[:, (width-height)//2: (width+height)//2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to resize the image to a specified resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img, res):\n",
    "    return cv2.resize(img, res, interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A module that recognises cat faces. We will be using the [Cat Frontal Face Haar Cascade](https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalcatface_extended.xml) contributed by Joseph Howse provided on the OpenCV GitHub repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValidCat(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cascade = cv2.CascadeClassifier('./haarcascade_frontalcatface.xml')\n",
    "    faces = cascade.detectMultiScale(gray, 1.1, 3) #image, reject levels, level weight\n",
    "    return len(faces)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isValidCat(crop_square('./cats_source/122.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, a function to generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(input_dir, output_dir, res, num_images):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    input_files = os.listdir(input_dir)\n",
    "    img_len = len(input_files)\n",
    "    if(img_len<num_images):\n",
    "        raise Exception(\"Not enough images in source directory\")\n",
    "    count=1\n",
    "    for file in input_files:\n",
    "        if(count>=num_images):\n",
    "            break\n",
    "        try:\n",
    "            destination_path = os.path.join(output_dir, str(count))+'.jpg'\n",
    "            cropped_image = crop_square(os.path.join(input_dir, file))\n",
    "            if(not isValidCat(cropped_image)):\n",
    "                continue\n",
    "                            \n",
    "            resized_image = resize(cropped_image, res)\n",
    "            if(count%128==0):\n",
    "                print(count, \" images processed\")\n",
    "            cv2.imwrite(destination_path, resized_image)\n",
    "            count+=1\n",
    "        except AttributeError:\n",
    "            continue    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify the parameters globally and watch the script work its magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128  images processed\n",
      "256  images processed\n",
      "384  images processed\n",
      "512  images processed\n",
      "640  images processed\n",
      "768  images processed\n",
      "896  images processed\n",
      "1024  images processed\n",
      "1152  images processed\n",
      "1280  images processed\n",
      "1408  images processed\n",
      "1536  images processed\n",
      "1664  images processed\n",
      "1792  images processed\n",
      "1920  images processed\n",
      "2048  images processed\n",
      "2176  images processed\n",
      "2304  images processed\n",
      "2432  images processed\n"
     ]
    }
   ],
   "source": [
    "generate_dataset('./cats_source', './cats_processed', (256,256), 4096)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
